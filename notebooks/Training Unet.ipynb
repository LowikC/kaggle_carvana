{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.INTER_NEAREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense, Activation, AveragePooling2D, Cropping2D, Reshape, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras import backend as K\n",
    "from keras.losses import mean_squared_error, binary_crossentropy\n",
    "from keras.preprocessing.image import Iterator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Reshape, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "import tensorflow as tf\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "from pkg_resources import parse_version\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unet_down_block(x, n_filters, block_id, with_maxpool=True, activation=\"elu\", crop=False):\n",
    "    padding = 'valid' if crop else 'same'\n",
    "    y = Conv2D(n_filters, (3, 3), activation=activation, \n",
    "               padding=padding, name=\"conv{}_1\".format(block_id))(x)\n",
    "    y = Conv2D(n_filters, (3, 3), activation=activation,\n",
    "               padding=padding, name=\"conv{}_2\".format(block_id))(y)\n",
    "    if not with_maxpool:\n",
    "        return y\n",
    "    \n",
    "    pool = MaxPooling2D(pool_size=(2, 2), name=\"max_pool{}\".format(block_id))(y)\n",
    "    return y, pool    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unet_up_block(x, y, n_filters, block_id, activation=\"elu\", crop=False):\n",
    "    padding = 'valid' if crop else 'same'\n",
    "    up_x = UpSampling2D(size=(2, 2), name=\"upsample{}\".format(block_id))(x)\n",
    "    \n",
    "    # Compute crop needed to have the same shape for up_x and y\n",
    "    if crop:\n",
    "        _, hx, wx, _ = up_x.shape\n",
    "        _, hy, wy, _ = y.shape\n",
    "        cropy = int(hy - hx)//2\n",
    "        cropx = int(wy - wx)//2\n",
    "        crop_y = Cropping2D(cropping=((cropy, cropy), (cropx, cropx)),\n",
    "                            name=\"crop{}\".format(block_id))(y)\n",
    "        print(\"Crop: \", cropy, cropx)\n",
    "    else:\n",
    "        crop_y = y\n",
    "    up = concatenate([up_x, crop_y], axis=-1,\n",
    "                     name=\"concat{}\".format(block_id))\n",
    "    print(up.shape)\n",
    "    up = Conv2D(n_filters, (3, 3), \n",
    "                activation=activation,\n",
    "                padding=padding,\n",
    "                name=\"conv{}_1\".format(block_id))(up)\n",
    "    print(up.shape)\n",
    "    up = Conv2D(n_filters, (3, 3),\n",
    "                activation=activation,\n",
    "                padding=padding,\n",
    "                name=\"conv{}_2\".format(block_id))(up)\n",
    "    print(up.shape)\n",
    "    return up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unet(im_height, im_width, n_channels=3,\n",
    "             n_filters=[64, 128, 256, 512, 1024]):\n",
    "    inputs = Input((im_height, im_width, n_channels))\n",
    "    \n",
    "    conv1, pool1 = unet_down_block(inputs, n_filters[0], 1)\n",
    "    conv2, pool2 = unet_down_block(pool1,  n_filters[1], 2)\n",
    "    conv3, pool3 = unet_down_block(pool2,  n_filters[2], 3)\n",
    "    conv4, pool4 = unet_down_block(pool3,  n_filters[3], 4)\n",
    "    conv5 = unet_down_block(pool4, n_filters[4], 5, with_maxpool=False)\n",
    "    \n",
    "    conv6 = unet_up_block(conv5, conv4, n_filters[3], 6)\n",
    "    conv7 = unet_up_block(conv6, conv3, n_filters[2], 7)\n",
    "    conv8 = unet_up_block(conv7, conv2, n_filters[1], 8)\n",
    "    conv9 = unet_up_block(conv8, conv1, n_filters[0], 9)\n",
    "    \n",
    "    segmentation = Conv2D(1, (1, 1), activation='sigmoid', name=\"segmentation\")(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[segmentation], name=\"unet\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 20, 30, 384)\n",
      "(?, 20, 30, 128)\n",
      "(?, 20, 30, 128)\n",
      "(?, 40, 60, 192)\n",
      "(?, 40, 60, 64)\n",
      "(?, 40, 60, 64)\n",
      "(?, 80, 120, 96)\n",
      "(?, 80, 120, 32)\n",
      "(?, 80, 120, 32)\n",
      "(?, 160, 240, 48)\n",
      "(?, 160, 240, 16)\n",
      "(?, 160, 240, 16)\n"
     ]
    }
   ],
   "source": [
    "unet = get_unet( 160, 240, 3, n_filters=[16, 32, 64, 128, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_batch = np.ones((2, 160, 240, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 160, 240, 1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.predict(test_batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NonValidPatch(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PatchIterator(Iterator):\n",
    "    def __init__(self, root_dir, image_ids,\n",
    "                 n_samples_per_image=160,\n",
    "                 target_size=(160, 240),\n",
    "                 crop_size=(160, 240),\n",
    "                 batch_size=4, shuffle=True, seed=42,\n",
    "                 debug_dir=None):\n",
    "        self.n_consecutives_samples_per_image = 1\n",
    "        self.image_ids = image_ids\n",
    "        self.root_dir = root_dir\n",
    "        self.debug_dir = debug_dir\n",
    "        self.n_samples_per_image = n_samples_per_image\n",
    "        self.target_size = target_size\n",
    "        self.crop_size = crop_size\n",
    "        self.n_indices = len(self.image_ids) * self.n_samples_per_image\n",
    "        if self.debug_dir:\n",
    "            os.makedirs(self.debug_dir, exist_ok=True)\n",
    "        super(PatchIterator, self).__init__(self.n_indices,\n",
    "                                            batch_size//self.n_consecutives_samples_per_image,\n",
    "                                            shuffle, seed)\n",
    "\n",
    "    def normalize_x(self, x):\n",
    "        x[..., 0] -= 127\n",
    "        x[..., 1] -= 127\n",
    "        x[..., 2] -= 127\n",
    "        return x\n",
    "    \n",
    "    def random_transform(self, x, y):\n",
    "        return x, y\n",
    "    \n",
    "    def sample(self, img, mask):\n",
    "        h, w, _ = img.shape\n",
    "        bx = np.zeros((self.n_consecutives_samples_per_image,\n",
    "                        self.target_size[0], \n",
    "                        self.target_size[1],\n",
    "                        3),\n",
    "                      dtype=np.uint8)\n",
    "        by = np.zeros((self.n_consecutives_samples_per_image,\n",
    "                        self.crop_size[0], \n",
    "                        self.crop_size[1]),\n",
    "                      dtype=np.uint8)\n",
    "        for i in range(self.n_consecutives_samples_per_image):\n",
    "            if w - self.target_size[1] - 1 > 0 and h - self.target_size[0] - 1 > 0:\n",
    "                sx = np.random.randint(0, w - self.target_size[1] - 1)\n",
    "                sy = np.random.randint(0, h - self.target_size[0] - 1)\n",
    "            else:\n",
    "                sx = 0\n",
    "                sy = 0\n",
    "            img_patch = img[sy: sy + self.target_size[0],\n",
    "                            sx: sx + self.target_size[1], ...]\n",
    "            mask_patch = mask[sy: sy + self.target_size[0],\n",
    "                              sx: sx + self.target_size[1]]\n",
    "            img_patch, mask_patch = self.random_transform(img_patch, mask_patch)\n",
    "            crop_sx = (self.target_size[1] - self.crop_size[1])//2\n",
    "            crop_sy = (self.target_size[0] - self.crop_size[0])//2\n",
    "            mask_patch_crop = mask_patch[crop_sy: crop_sy + self.crop_size[0],\n",
    "                                         crop_sx: crop_sx + self.crop_size[1]]\n",
    "            bx[i, ...] = img_patch\n",
    "            by[i, ...] = mask_patch_crop\n",
    "        return bx, by\n",
    "    \n",
    "    def next(self):\n",
    "        \"\"\"For python 2.x.\n",
    "        # Returns\n",
    "            The next batch.\n",
    "        \"\"\"\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch.\n",
    "        with self.lock:\n",
    "            index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "                \n",
    "        batch_x = np.zeros((current_batch_size * self.n_consecutives_samples_per_image,\n",
    "                            self.target_size[0],\n",
    "                            self.target_size[1],\n",
    "                            3),\n",
    "                           dtype=np.uint8)\n",
    "        batch_y = np.zeros((current_batch_size * self.n_consecutives_samples_per_image,\n",
    "                            self.crop_size[0],\n",
    "                            self.crop_size[1],\n",
    "                            1),\n",
    "                           dtype=np.uint8)\n",
    "        \n",
    "        # For each index, we load the data and sample randomly n_consecutives_samples_per_image patches\n",
    "        for i, j in enumerate(index_array):\n",
    "            index = j // self.n_samples_per_image\n",
    "            image_id = self.image_ids[index]\n",
    "            img = np.array(Image.open(os.path.join(self.root_dir, \"train_240x160\", image_id + \".png\")))\n",
    "            mask = np.array(Image.open(os.path.join(self.root_dir, \"train_masks_240x160\", image_id + \"_mask.png\")))\n",
    "            #weights = np.array(Image.open(os.path.join(self.root_dir, \"train_weights\", image_id + \".png\")))\n",
    "                \n",
    "            x, y = self.sample(img, mask) #  ,weights\n",
    "            batch_x[i*self.n_consecutives_samples_per_image:(i+1)*self.n_consecutives_samples_per_image, ...] = x\n",
    "            batch_y[i*self.n_consecutives_samples_per_image:(i+1)*self.n_consecutives_samples_per_image, :, :, 0] = y\n",
    "        \n",
    "        if self.debug_dir:\n",
    "            for i in range(batch_x.shape[0]):\n",
    "                cv2.imwrite(os.path.join(self.debug_dir, \"{:02d}_img.png\".format(i)), batch_x[i, ...])\n",
    "                cv2.imwrite(os.path.join(self.debug_dir, \"{:02d}_mask.png\".format(i)), batch_y[i, ...] * 255)\n",
    "        return self.normalize_x(batch_x), batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/train.json\", \"r\") as jfile:\n",
    "    train_ids = json.load(jfile)\n",
    "\n",
    "with open(\"../data/val.json\", \"r\") as jfile:\n",
    "    val_ids = json.load(jfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainPatchesGenerator = PatchIterator(\"/home/lowik/carvana/data\", train_ids)\n",
    "valPatchesGenerator = PatchIterator(\"/home/lowik/carvana/data\", val_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for bx, by in trainPatchesGenerator:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 160, 240, 1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "smooth = 1e-6\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=1e-4, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "unet.compile(optimizer=sgd, loss=dice_coef_loss, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "20/20 [==============================] - 33s - loss: -0.5511 - acc: 0.7834 - val_loss: -0.5398 - val_acc: 0.8006\n",
      "Epoch 2/2\n",
      "20/20 [==============================] - 39s - loss: -0.5697 - acc: 0.7917 - val_loss: -0.5809 - val_acc: 0.8101\n"
     ]
    }
   ],
   "source": [
    "h = unet.fit_generator(trainPatchesGenerator, 20, epochs=2,\n",
    "                       verbose=1,\n",
    "                       validation_data=valPatchesGenerator, validation_steps=10,\n",
    "                       class_weight=[0.2, 0.8],\n",
    "                       max_q_size=1, workers=1, pickle_safe=False,\n",
    "                       initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
